import os
import json
import requests
import re
from typing import Dict, List, Optional, Tuple
from huggingface_hub import InferenceClient
from server.config.config import Config
from .text_processor import TextPreprocessor


class HuggingFaceHandler:
    def __init__(self):
        """Inicializa o cliente Hugging Face com NLP"""
        self.api_key = Config.HF_TOKEN
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # Inicializar pr√©-processador NLP
        self.text_processor = TextPreprocessor(language='portuguese')
        
        # DEBUG: Verificar token
        print(f"üîë Token HF (primeiros 10 chars): {self.api_key[:10] if self.api_key else 'NONE'}")
        print(f"üìù Token v√°lido? {self.api_key and self.api_key.startswith('hf_')}")
        
        # Modelos
        self.classification_model = "facebook/bart-large-mnli"
        self.summarization_model = "Falconsai/text_summarization"
        self.text_generation_model = "google/flan-t5-large"
        
        # URLs atualizadas
        self.api_base_url = "https://router.huggingface.co"
        self.old_api_base_url = "https://api-inference.huggingface.co"
        
        # Inicializar client
        self.client = None
        if self.api_key and self.api_key.startswith("hf_"):
            try:
                print("üîÑ Tentando inicializar InferenceClient...")
                self.client = InferenceClient(token=self.api_key)
                print(f"‚úÖ HuggingFace Handler inicializado com NLP")
                print(f"üîç Client dispon√≠vel: {self.client is not None}")
            except Exception as e:
                print(f"‚ö†Ô∏è Erro InferenceClient: {e}")
                self.client = None
        else:
            print("‚ö†Ô∏è Token HF inv√°lido ou ausente")

    def is_available(self):
        """Verifica se est√° dispon√≠vel"""
        return self.client is not None and self.api_key and self.api_key.startswith("hf_")

    def analyze_email(self, email_content: str, attachments_text: str = "") -> Dict:
        """
        Analisa um email usando Hugging Face com pr√©-processamento NLP.
        
        Returns:
            Dict com an√°lise completa
        """
        try:
            print("=" * 60)
            print("ü§ñ Hugging Face + NLP analisando...")
            
            # PR√â-PROCESSAMENTO NLP
            print("\nüîß Pr√©-processamento NLP...")
            processed_email = self.text_processor.preprocess_for_classification(email_content)
            
            print(f"üìß Conte√∫do ORIGINAL: {len(email_content)} chars")
            print(f"üìä Conte√∫do PROCESSADO: {len(processed_email)} chars")
            print(f"üìã Amostra processada: {processed_email[:200]}...")
            
            # Processar anexos se houver
            processed_attachments = ""
            if attachments_text:
                processed_attachments = self.text_processor.preprocess_for_classification(attachments_text)
                print(f"üìé Anexos processados: {len(processed_attachments)} chars")
            
            # Extrair metadados
            metadata = self.text_processor.get_email_metadata(email_content)
            print(f"üìä Metadados: {metadata}")
            
            # Preparar conte√∫do completo (processado)
            full_content = processed_email
            if processed_attachments:
                full_content += f" [ANEXOS] {processed_attachments}"
            
            # Limitar tamanho para APIs
            if len(full_content) > 1000:
                full_content = full_content[:1000]
                print(f"üìù Conte√∫do truncado para 1000 chars")
            
            # 1. CLASSIFICA√á√ÉO
            print("\nüîç Iniciando classifica√ß√£o com NLP...")
            classification = self._classify_content(full_content, email_content)
            print(f"üìä Resultado classifica√ß√£o: {classification}")
            
            # 2. RESUMO
            print("\nüìù Gerando resumo...")
            summary_content = self.text_processor.preprocess_for_summarization(email_content[:500])
            summary = self._summarize_content(summary_content)
            print(f"üìÑ Resumo gerado: {summary[:100]}...")
            
            # Processar resultados
            categoria_hf = classification.get("category", "email normal de rotina")
            confianca = classification.get("confidence", 0.5)
            
            print(f"\nüéØ Categoria HF: {categoria_hf}")
            print(f"üìà Confian√ßa: {confianca:.2f}")
            
            # Mapear categoria
            categoria = self._map_category(categoria_hf, email_content)
            print(f"üó∫Ô∏è Categoria mapeada: {categoria}")
            
            # HEUR√çSTICA MELHORADA COM NLP
            categoria, utilidade = self._apply_heuristics_with_nlp(
                email_content, categoria, confianca, metadata
            )
            
            # 3. RESPOSTA
            print("\nüí¨ Gerando resposta...")
            response_text = self._generate_response(email_content[:300], categoria, classification)
            print(f"‚úâÔ∏è Resposta gerada: {response_text[:100]}...")
            
            # 4. TAGS COM PALAVRAS-CHAVE NLP
            print("\nüè∑Ô∏è Gerando tags com NLP...")
            tags = self._generate_tags_with_nlp(email_content, categoria, metadata)
            print(f"üè∑Ô∏è Tags geradas: {tags}")
            
            # 5. PALAVRAS-CHAVE EXTRAS
            keywords = self.text_processor.extract_keywords(email_content, top_n=5)
            print(f"üîë Palavras-chave extra√≠das: {keywords}")
            
            # Resultado final
            resultado = {
                'utilidade': utilidade,
                'categoria': categoria,
                'resumo': summary[:80] if summary else f"Classificado como {categoria}",
                'acao_necessaria': categoria in ["CURRICULO", "FINANCEIRO", "IMPORTANTE", "PHISHING", "EDUCACIONAL"],
                'tags': tags,
                'resposta': response_text,
                'fonte': 'huggingface_ia_nlp' if self.is_available() else 'fallback_nlp',
                'metadata': {
                    'palavras_chave': keywords,
                    'contagem_palavras': metadata['word_count'],
                    'tem_anexos': metadata['has_attachments'],
                    'tem_links': metadata['has_links']
                }
            }
            
            print(f"\n‚úÖ AN√ÅLISE FINALIZADA COM NLP:")
            print(f"   Categoria: {resultado['categoria']}")
            print(f"   Utilidade: {resultado['utilidade']:.2f}")
            print(f"   Tags: {resultado['tags'][:4]}")
            print(f"   Palavras-chave: {resultado['metadata']['palavras_chave']}")
            print("=" * 60)
            
            return resultado
            
        except Exception as e:
            print(f"‚ùå Erro HF: {e}")
            import traceback
            traceback.print_exc()
            return self._create_default_analysis(email_content)

    def _classify_content(self, content: str, original_content: str = "") -> Dict:
        """Classifica√ß√£o zero-shot com conte√∫do pr√©-processado"""
        try:
            print(f"\nüìä _classify_content() com NLP")
            print(f"üìù Conte√∫do processado: {content[:150]}...")
            
            # LABELS OTIMIZADAS PARA PORTUGU√äS
            candidate_labels = [
                "curr√≠culo profissional candidatura emprego vaga trabalho",
                "email profissional corporativo trabalho reuni√£o projeto equipe",
                "documento financeiro nota fiscal boleto pagamento fatura",
                "urgente importante prioridade emerg√™ncia aten√ß√£o", 
                "comunica√ß√£o institucional educacional matr√≠cula curso universidade",
                "promo√ß√£o comercial spam marketing publicidade oferta",
                "phishing fraude golpe seguran√ßa suspeito perigoso banco senha",
                "email normal rotina comunica√ß√£o mensagem contato"
            ]
            
            print(f"üè∑Ô∏è Labels dispon√≠veis: {candidate_labels}")
            
            # PRIMEIRO: Verificar se √© reuni√£o/profissional
            if original_content:
                reuniao_keywords = ['reuniao', 'reuni√£o', 'pauta', 'equipe', 'projeto', 'comercial']
                content_lower = original_content.lower()
                reuniao_score = sum(1 for kw in reuniao_keywords if kw in content_lower)
                
                if reuniao_score >= 2:
                    print(f"üéØ HEUR√çSTICA REUNI√ÉO: Score {reuniao_score}")
                    return {
                        "category": "email profissional corporativo trabalho reuni√£o projeto equipe",
                        "confidence": 0.85
                    }
            
            # SEGUNDO: Verificar se √© curr√≠culo
            if original_content:
                curriculo_keywords = ['curricul', 'cv', 'curriculo', 'resume', 'portfolio', 
                                     'linkedin', 'github', 'experiencia', 'formacao', 
                                     'habilidades', 'competencias', 'objetivo']
                content_lower = original_content.lower()
                curriculo_score = sum(1 for kw in curriculo_keywords if kw in content_lower)
                
                if curriculo_score >= 3:
                    print(f"üéØ HEUR√çSTICA CURR√çCULO: Score {curriculo_score}")
                    return {
                        "category": "curr√≠culo profissional candidatura emprego vaga trabalho",
                        "confidence": 0.85
                    }
            
            # TENTAR COM InferenceClient
            if self.client and self.is_available():
                print("üîÑ Tentando InferenceClient.zero_shot_classification...")
                try:
                    safe_content = content[:800] if len(content) > 800 else content
                    
                    result = self.client.zero_shot_classification(
                        safe_content,
                        candidate_labels=candidate_labels,
                        multi_label=False
                    )
                    
                    print(f"üìä Tipo da resposta: {type(result)}")
                    
                    # Formato novo do InferenceClient
                    if hasattr(result, 'labels') and hasattr(result, 'scores'):
                        labels = result.labels
                        scores = result.scores
                        
                        if labels and scores:
                            best_index = scores.index(max(scores))
                            best_label = labels[best_index]
                            best_score = scores[best_index]
                            
                            print(f"‚úÖ Melhor resultado: {best_label} ({best_score:.3f})")
                            return {
                                "category": best_label,
                                "confidence": float(best_score)
                            }
                    
                    # Formato antigo
                    elif isinstance(result, dict) and 'labels' in result and 'scores' in result:
                        labels = result["labels"]
                        scores = result["scores"]
                        
                        if labels and scores:
                            best_index = scores.index(max(scores))
                            best_label = labels[best_index]
                            best_score = scores[best_index]
                            
                            print(f"‚úÖ Melhor resultado: {best_label} ({best_score:.3f})")
                            return {
                                "category": best_label,
                                "confidence": float(best_score)
                            }
                    
                    else:
                        print("‚ö†Ô∏è Formato de resposta inesperado do InferenceClient")
                        return self._fallback_classification_with_nlp(content, original_content)
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro InferenceClient: {e}")
                    return self._fallback_classification_with_nlp(content, original_content)
            
            # Se InferenceClient n√£o dispon√≠vel ou falhou, usar heur√≠stica NLP
            print("üîÑ InferenceClient n√£o dispon√≠vel, usando heur√≠stica NLP...")
            return self._fallback_classification_with_nlp(content, original_content)
                
        except Exception as e:
            print(f"‚ùå Erro classifica√ß√£o: {e}")
            return self._fallback_classification_with_nlp(content, original_content)

    def _fallback_classification_with_nlp(self, content: str, original_content: str = "") -> Dict:
        """Fallback com heur√≠stica e NLP - MELHORADA"""
        print(f"\nüîÑ Usando classifica√ß√£o heur√≠stica com NLP")
        
        # Usar conte√∫do original se dispon√≠vel
        analysis_content = original_content if original_content else content
        keywords = self.text_processor.extract_keywords(analysis_content, top_n=15)
        print(f"üîë Palavras-chave extra√≠das: {keywords}")
        
        content_lower = analysis_content.lower()
        
        # 0. PRIMEIRO: Verificar se √© REUNI√ÉO/PROFISSIONAL
        reuniao_keywords = ['reuniao', 'reuni√£o', 'pauta', 'equipe', 'projeto', 'comercial',
                           'relatorio', 'relat√≥rio', 'apresentacao', 'apresenta√ß√£o']
        reuniao_score = sum(1 for kw in reuniao_keywords if kw in content_lower)
        
        if reuniao_score >= 2:
            print(f"‚úÖ HEUR√çSTICA REUNI√ÉO/PROFISSIONAL: Score {reuniao_score}")
            return {
                "category": "email profissional corporativo trabalho reuni√£o projeto equipe",
                "confidence": min(0.95, 0.7 + (reuniao_score * 0.05))
            }
        
        # 1. Verificar se √© EDUCACIONAL
        educacional_keywords = ['matricula', 'matr√≠cula', 'curso', 'aluno', 'secretaria', 
                               'universidade', 'faculdade', 'disciplina', 'calend√°rio', 
                               'acad√™mico', 'professor', 'academico', 'campus', 'turma',
                               'p√≥s-gradua√ß√£o', 'gradua√ß√£o', 'semestre', 'nota', 'prova']
        
        educacional_score = 0
        for kw in educacional_keywords:
            if kw in content_lower:
                educacional_score += 1
        
        if educacional_score >= 3:
            print(f"‚úÖ HEUR√çSTICA EDUCACIONAL: Score {educacional_score}")
            return {
                "category": "comunica√ß√£o institucional educacional matr√≠cula curso universidade",
                "confidence": min(0.95, 0.7 + (educacional_score * 0.05))
            }
        
        # 2. Verificar se √© curr√≠culo
        curriculo_keywords = ['curricul', 'cv', 'vag', 'empreg', 'candidatur', 
                             'linkedin', 'entrevist', 'profissional', 'trabalh',
                             'desenvolvedor', 'full', 'stack', 'junior', 'senior',
                             'experiencia', 'formacao', 'habilidades', 'objetivo']
        
        curriculo_score = 0
        for kw in curriculo_keywords:
            if kw in content_lower:
                curriculo_score += 1
        
        if curriculo_score >= 3:
            print(f"‚úÖ HEUR√çSTICA CURR√çCULO: Score {curriculo_score}")
            return {
                "category": "curr√≠culo profissional candidatura emprego vaga trabalho",
                "confidence": min(0.95, 0.7 + (curriculo_score * 0.04))
            }
        
        # 3. Verificar se √© financeiro
        financeiro_keywords = ['nota fiscal', 'nfe', 'bolet', 'fatur', 'pagament', 
                              'financeir', 'impost', 'tribut', 'tax', 'valor', 
                              'reais', 'compra', 'venda', 'transa√ß√£o']
        
        financeiro_score = 0
        for kw in financeiro_keywords:
            if kw in content_lower:
                financeiro_score += 2 if 'nota fiscal' in kw or 'boleto' in kw or 'fatura' in kw else 1
        
        if financeiro_score >= 3:
            print(f"‚úÖ HEUR√çSTICA FINANCEIRO: Score {financeiro_score}")
            return {
                "category": "documento financeiro nota fiscal boleto pagamento fatura",
                "confidence": min(0.95, 0.6 + (financeiro_score * 0.05))
            }
        
        # 4. Verificar se √© phishing
        phishing_keywords = ['clicar aqui', 'atualizar dados', 'sua conta', 'senha expira',
                            'conta suspensa', 'acesso bloqueado', 'urgentemente',
                            'banco', 'cart√£o de cr√©dito', 'cpf', 'rg', 'n√∫mero do cart√£o',
                            'pix', 'seguran√ßa', 'suspeito', 'fraude', 'golpe']
        
        phishing_score = 0
        for kw in phishing_keywords:
            if kw in content_lower:
                phishing_score += 2 if any(word in kw for word in ['senha', 'conta', 'banco', 'cart√£o', 'cpf', 'rg']) else 1
        
        if phishing_score >= 3:
            print(f"‚úÖ HEUR√çSTICA PHISHING: Score {phishing_score}")
            return {
                "category": "phishing fraude golpe seguran√ßa suspeito perigoso banco senha",
                "confidence": min(0.95, 0.6 + (phishing_score * 0.05))
            }
        
        # 5. Verificar se √© spam/promo√ß√£o
        spam_keywords = ['descont', 'promoc', 'ofert', 'gratuit', 'fret', 
                        'exclusiv', 'limit', 'aproveit', 'comerc', 'compre agora',
                        'clique para comprar', 's√≥ hoje', '√∫ltima chance', 'corra']
        
        spam_score = 0
        for kw in spam_keywords:
            if kw in content_lower:
                spam_score += 2 if any(word in kw for word in ['desconto', 'promo√ß√£o', 'oferta', 'gr√°tis']) else 1
        
        if spam_score >= 3:
            print(f"‚úÖ HEUR√çSTICA SPAM: Score {spam_score}")
            return {
                "category": "promo√ß√£o comercial spam marketing publicidade oferta",
                "confidence": min(0.95, 0.7 + (spam_score * 0.04))
            }
        
        # 6. Verificar se √© importante/urgente
        importante_keywords = ['urgent', 'importante', 'prioridade', 'emerg√™ncia', 
                              'aten√ß√£o', 'cr√≠tico', 'urgentemente', 'prazo final']
        
        importante_score = 0
        for kw in importante_keywords:
            if kw in content_lower:
                importante_score += 1
        
        if importante_score >= 2:
            print(f"‚úÖ HEUR√çSTICA IMPORTANTE: Score {importante_score}")
            return {
                "category": "urgente importante prioridade emerg√™ncia aten√ß√£o",
                "confidence": min(0.95, 0.7 + (importante_score * 0.05))
            }
        
        # 7. Default: email normal de rotina
        print(f"üìã HEUR√çSTICA DEFAULT: Email de rotina")
        return {
            "category": "email normal rotina comunica√ß√£o mensagem contato",
            "confidence": 0.5
        }

    def _apply_heuristics_with_nlp(self, content: str, categoria: str, 
                                 confianca: float, metadata: Dict) -> Tuple[str, float]:
        """Aplica heur√≠sticas avan√ßadas com NLP"""
        
        # Utilidade base por categoria - INCLUINDO EDUCACIONAL
        utility_base = {
            "CURRICULO": 0.92,
            "FINANCEIRO": 0.88,
            "IMPORTANTE": 0.85,
            "EDUCACIONAL": 0.82,
            "PROFISSIONAL": 0.78,
            "ROTINA": 0.45,
            "SPAM": 0.15,
            "PHISHING": 0.05
        }
        
        utilidade = utility_base.get(categoria, 0.5)
        content_lower = content.lower()
        
        # DETEC√á√ÉO DE EDUCACIONAL (se n√£o foi detectado antes)
        if categoria != "EDUCACIONAL":
            educacional_indicators = ['matricula', 'matr√≠cula', 'curso', 'aluno', 'secretaria', 
                                     'universidade', 'faculdade', 'disciplina', 'calend√°rio', 
                                     'acad√™mico', 'professor', 'campus', 'turma', 'p√≥s-gradua√ß√£o']
            
            educacional_score = sum(1 for indicator in educacional_indicators if indicator in content_lower)
            
            if educacional_score >= 3:
                print(f"üéØ HEUR√çSTICA EDUCACIONAL: Score {educacional_score}")
                categoria = "EDUCACIONAL"
                utilidade = 0.82
                confianca = max(confianca, 0.7)
        
        # DETEC√á√ÉO DE CURR√çCULO - MAIS ROBUSTA
        if categoria != "CURRICULO":
            cv_indicators = ['curricul', 'cv', 'vag', 'empreg', 'candidatur', 
                            'linkedin', 'entrevist', 'desenvolvedor', 'full stack',
                            'junior', 'senior', 'pleno', 'github', 'portifolio',
                            'experiencia', 'formacao', 'habilidades']
            cv_score = sum(1 for indicator in cv_indicators if indicator in content_lower)
            
            has_formal_closure = any(word in content_lower for word in 
                                   ['atenciosamente', 'cordialmente', 'sinceramente', 
                                    'grato', 'obrigado', 'prezado', 'prezada'])
            
            has_contact_info = any(word in content_lower for word in 
                                 ['@', 'telefone', 'celular', 'email', 'github', 'linkedin'])
            
            # Se tem muitos indicadores de curr√≠culo, reclassificar
            if cv_score >= 5 or (cv_score >= 3 and has_formal_closure and has_contact_info):
                print(f"üéØ HEUR√çSTICA CURR√çCULO FORTE: Score {cv_score}")
                categoria = "CURRICULO"
                utilidade = 0.92
                confianca = max(confianca, 0.8)
        
        # DETEC√á√ÉO DE IMPORTANTE (sobrescreve outras categorias exceto PHISHING)
        if categoria not in ["PHISHING", "CURRICULO", "FINANCEIRO"]:
            importante_indicators = ['urgente', 'importante', 'prioridade', 'emerg√™ncia', 
                                   'cr√≠tico', 'urgentemente', 'prazo final', 'imediatamente']
            
            importante_score = sum(1 for indicator in importante_indicators if indicator in content_lower)
            
            if importante_score >= 2:
                print(f"üéØ HEUR√çSTICA IMPORTANTE: Score {importante_score}")
                # Se for educacional e importante, manter como EDUCACIONAL mas aumentar utilidade
                if categoria == "EDUCACIONAL":
                    utilidade = 0.88
                else:
                    categoria = "IMPORTANTE"
                    utilidade = 0.85
        
        # Ajustar utilidade baseado na confian√ßa
        utilidade = utilidade * (0.6 + 0.4 * confianca)
        utilidade = min(0.99, max(0.05, utilidade))
        
        print(f"üìä Utilidade final: {utilidade:.2f} (base ajustada para categoria)")
        
        return categoria, utilidade

    def _summarize_content(self, content: str) -> str:
        """Gera resumo do conte√∫do"""
        try:
            print(f"\nüìù _summarize_content()")
            
            processed_content = self.text_processor.preprocess_for_summarization(content)
            
            if self.client and self.is_available():
                print(f"üîÑ Tentando summarization...")
                try:
                    result = self.client.summarization(
                        processed_content[:600],
                        model=self.summarization_model
                    )
                    
                    if hasattr(result, 'summary_text'):
                        summary = result.summary_text
                    elif isinstance(result, str):
                        summary = result
                    elif isinstance(result, dict) and 'summary_text' in result:
                        summary = result['summary_text']
                    else:
                        summary = self._extract_lead_sentences(content)
                    
                    print(f"üìÑ Resumo: {summary[:120]}...")
                    return summary
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro summarization: {e}")
            
            return self._extract_lead_sentences(content)
                
        except Exception as e:
            print(f"‚ùå Erro resumo: {e}")
            return content[:100] + "..."

    def _extract_lead_sentences(self, content: str, num_sentences: int = 3) -> str:
        """Extrai as primeiras frases significativas"""
        if not content:
            return ""
        
        # Usar regex melhorado para separar frases
        sentences = re.split(r'(?<=[.!?])\s+', content)
        
        valid_sentences = [
            s.strip() for s in sentences 
            if s.strip() and len(s.strip().split()) >= 4
        ]
        
        lead_sentences = valid_sentences[:num_sentences]
        
        if lead_sentences:
            summary = '. '.join(lead_sentences) + '.'
            if len(summary) > 120:
                summary = summary[:117] + '...'
            return summary
        
        return content[:100] + "..."

    def _generate_response(self, content: str, categoria_real: str, 
                          classification: Optional[Dict] = None) -> str:
        """Gera resposta apropriada"""
        try:
            print(f"\nüí¨ _generate_response() - Categoria: {categoria_real}")
            
            # Respostas melhoradas - INCLUINDO EDUCACIONAL
            default_responses = {
                "CURRICULO": "‚úÖ **Curr√≠culo recebido com sucesso!** Agradecemos o envio do seu curr√≠culo. Analisaremos suas qualifica√ß√µes e entraremos em contato em breve. Mantenha seu LinkedIn e GitHub atualizados!",
                "FINANCEIRO": "üìÑ **Documento financeiro registrado.** Confirmamos o recebimento. Nossa equipe far√° a an√°lise e retornar√° em at√© 48 horas √∫teis.",
                "IMPORTANTE": "üö® **Mensagem importante identificada.** Daremos prioridade √† an√°lise deste assunto e retornaremos o mais breve poss√≠vel.",
                "EDUCACIONAL": "üéì **Comunica√ß√£o educacional recebida.** Confirmamos o recebimento da sua mensagem institucional. Retornaremos em breve.",
                "PROFISSIONAL": "üíº **Email profissional recebido.** Agradecemos seu contato. Analisaremos o conte√∫do e retornaremos dentro do prazo de 24 horas √∫teis.",
                "ROTINA": "üìß **Mensagem recebida.** Agradecemos seu contato. Retornaremos em breve.",
                "SPAM": "üì≠ **Email promocional detectado.** Esta mensagem foi classificada como material promocional. Filtro ativo.",
                "PHISHING": "‚ö†Ô∏è **ALERTA DE SEGURAN√áA:** Email suspeito detectado. N√£o clique em links, n√£o forne√ßa informa√ß√µes pessoais e exclua esta mensagem. Entre em contato com o suporte se necess√°rio."
            }
            
            print(f"üìã Usando resposta padr√£o para {categoria_real}")
            return default_responses.get(categoria_real, default_responses["ROTINA"])
                
        except Exception as e:
            print(f"‚ùå Erro resposta: {e}")
            return "Mensagem recebida. Agradecemos seu contato."

    def _map_category(self, hf_category: str, content: str = "") -> str:
        """Mapeia categoria do modelo para categorias internas - COM EDUCACIONAL"""
        hf_lower = hf_category.lower()
        
        # PRIMEIRO: Verificar se √© educacional baseado no conte√∫do
        if content:
            educacional_keywords = ['matricula', 'matr√≠cula', 'curso', 'aluno', 'secretaria', 
                                   'universidade', 'faculdade', 'disciplina', 'calend√°rio', 
                                   'acad√™mico', 'professor', 'campus', 'turma']
            content_lower = content.lower()
            educacional_score = sum(1 for kw in educacional_keywords if kw in content_lower)
            
            if educacional_score >= 3:
                print(f"üéØ MAPEAMENTO EDUCACIONAL: {educacional_score} indicadores")
                return "EDUCACIONAL"
        
        # SEGUNDO: Verificar se √© curr√≠culo baseado no conte√∫do
        if content:
            curriculo_keywords = ['curricul', 'cv', 'resume', 'linkedin', 'github', 
                                 'experiencia', 'formacao', 'habilidades', 'objetivo',
                                 'candidatura', 'vaga', 'emprego']
            content_lower = content.lower()
            curriculo_score = sum(1 for kw in curriculo_keywords if kw in content_lower)
            
            if curriculo_score >= 3:
                print(f"üéØ MAPEAMENTO CURR√çCULO: {curriculo_score} indicadores")
                return "CURRICULO"
        
        # TERCEIRO: Verificar se √© profissional/reuni√£o baseado no conte√∫do
        if content:
            profissional_keywords = ['reuniao', 'reuni√£o', 'pauta', 'equipe', 'projeto',
                                    'relatorio', 'relat√≥rio', 'apresentacao', 'apresenta√ß√£o',
                                    'corporativo', 'comercial', 'empresa', 'neg√≥cio']
            content_lower = content.lower()
            profissional_score = sum(1 for kw in profissional_keywords if kw in content_lower)
            
            if profissional_score >= 2 and curriculo_score < 3:  # S√≥ se n√£o for curr√≠culo
                print(f"üéØ MAPEAMENTO PROFISSIONAL: {profissional_score} indicadores")
                return "PROFISSIONAL"
        
        # Mapeamento baseado na categoria do modelo (fallback)
        if any(word in hf_lower for word in ['curr√≠culo', 'curricul', 'emprego', 'vaga', 'candidatur', 'trabalho']):
            # Verificar se n√£o √© falso positivo para profissional
            if content and any(word in content.lower() for word in ['reuniao', 'reuni√£o', 'pauta', 'equipe']):
                print(f"üéØ CORRE√á√ÉO: Reuni√£o detectada, mapeando para PROFISSIONAL")
                return "PROFISSIONAL"
            return "CURRICULO"
        elif any(word in hf_lower for word in ['financeiro', 'nota fiscal', 'boleto', 'pagamento', 'fatura']):
            return "FINANCEIRO"
        elif any(word in hf_lower for word in ['urgente', 'importante', 'prioridade', 'emerg√™ncia']):
            return "IMPORTANTE"
        elif any(word in hf_lower for word in ['educacional', 'matr√≠cula', 'curso', 'universidade', 'institucional']):
            return "EDUCACIONAL"
        elif any(word in hf_lower for word in ['profissional', 'corporativo', 'reuni√£o', 'projeto', 'equipe']):
            return "PROFISSIONAL"
        elif any(word in hf_lower for word in ['promo√ß√£o', 'spam', 'marketing', 'publicidade']):
            return "SPAM"
        elif any(word in hf_lower for word in ['phishing', 'fraude', 'golpe', 'seguran√ßa', 'suspeito', 'perigoso']):
            return "PHISHING"
        else:
            return "ROTINA"

    def _generate_tags_with_nlp(self, content: str, category: str, metadata: Dict) -> List[str]:
        """Gera tags usando NLP"""
        print(f"\nüè∑Ô∏è _generate_tags_with_nlp() - Categoria: '{category}'")
        
        tags = [category.lower()]
        
        # Tags espec√≠ficas por categoria
        if category == "CURRICULO":
            tech_keywords = ['python', 'javascript', 'java', 'react', 'node', 'sql', 
                            'mysql', 'postgresql', 'docker', 'aws', 'github']
            content_lower = content.lower()
            
            tech_tags = [tech for tech in tech_keywords if tech in content_lower]
            tags.extend(tech_tags[:3])
            
            # Adicionar n√≠vel profissional
            if 'junior' in content_lower:
                tags.append('junior')
            elif 'senior' in content_lower or 's√™nior' in content_lower:
                tags.append('senior')
            elif 'pleno' in content_lower:
                tags.append('pleno')
            
            tags.extend(['curriculo', 'profissional', 'tecnologia'])
        
        elif category == "EDUCACIONAL":
            educacional_tags = ['ensino', 'aprendizado', 'institui√ß√£o', 'estudos']
            tags.extend(educacional_tags[:2])
        
        # Tags gen√©ricas
        keywords = self.text_processor.extract_keywords(content, top_n=6)
        tags.extend([kw for kw in keywords if len(kw) > 3][:3])
        
        category_tags = {
            "SPAM": ['comercial', 'promocao', 'marketing'],
            "FINANCEIRO": ['documento', 'financeiro', 'pagamento'],
            "PHISHING": ['seguran√ßa', 'alerta', 'fraude'],
            "IMPORTANTE": ['urgente', 'prioridade'],
            "PROFISSIONAL": ['corporativo', 'negocios', 'empresa'],
            "EDUCACIONAL": ['ensino', 'academico', 'estudo'],
            "ROTINA": ['comum', 'correspondencia']
        }
        
        tags.extend(category_tags.get(category, []))
        
        # Tags baseadas em metadados
        if metadata.get('has_attachments'):
            tags.append('com_anexo')
        if metadata.get('has_links'):
            tags.append('com_links')
            
        if metadata.get('word_count', 0) > 200:
            tags.append('longo')
        elif metadata.get('word_count', 0) < 50:
            tags.append('curto')
        
        # Remover duplicatas e limitar
        unique_tags = list(dict.fromkeys([tag for tag in tags if tag]))
        print(f"üìã Tags finais: {unique_tags[:8]}")
        
        return unique_tags[:10]

    def _create_default_analysis(self, email_content: str, metadata: Optional[Dict] = None) -> Dict:
        """An√°lise padr√£o com heur√≠stica NLP"""
        print(f"\nüîÑ _create_default_analysis() com NLP")
        
        if not email_content:
            return self._get_fallback_response("ROTINA")
        
        content_lower = email_content.lower()
        
        # Verificar se √© educacional
        educacional_indicators = ['matricula', 'matr√≠cula', 'curso', 'aluno', 'secretaria', 
                                 'universidade', 'faculdade', 'disciplina', 'calend√°rio']
        educacional_score = sum(1 for indicator in educacional_indicators if indicator in content_lower)
        
        if educacional_score >= 3:
            print(f"üéØ HEUR√çSTICA EDUCACIONAL: Score {educacional_score}")
            return self._get_fallback_response("EDUCACIONAL")
        
        # Verificar se √© curr√≠culo
        curriculo_indicators = ['curricul', 'cv', 'vaga', 'emprego', 'candidatura',
                               'linkedin', 'github', 'experiencia', 'formacao']
        curriculo_score = sum(1 for indicator in curriculo_indicators if indicator in content_lower)
        
        if curriculo_score >= 3:
            print(f"üéØ HEUR√çSTICA CURR√çCULO: Score {curriculo_score}")
            return self._get_fallback_response("CURRICULO")
        
        # Verificar SPAM
        spam_keywords = ['desconto', 'promo√ß√£o', 'oferta', 'gr√°tis', 'frete', 'promocao']
        spam_count = sum(1 for word in spam_keywords if word in content_lower)
        
        if spam_count >= 3:
            print(f"üéØ HEUR√çSTICA SPAM: {spam_count} palavras")
            return self._get_fallback_response("SPAM")
        
        # Verificar phishing
        phishing_indicators = ['clicar aqui', 'atualizar dados', 'sua conta', 'senha expira',
                              'conta suspensa', 'banco', 'cart√£o', 'cpf', 'rg']
        phishing_count = sum(1 for phrase in phishing_indicators if phrase in content_lower)
        
        if phishing_count >= 3:
            print(f"üéØ HEUR√çSTICA PHISHING: {phishing_count} indicadores")
            return self._get_fallback_response("PHISHING")
        
        # Verificar financeiro
        finance_indicators = ['nota fiscal', 'boleto', 'fatura', 'pagamento', 'nfe']
        if any(indicator in content_lower for indicator in finance_indicators):
            print(f"üéØ HEUR√çSTICA FINANCEIRO")
            return self._get_fallback_response("FINANCEIRO")
        
        # Verificar importante
        important_indicators = ['urgente', 'importante', 'prioridade', 'emerg√™ncia']
        if any(indicator in content_lower for indicator in important_indicators):
            print(f"üéØ HEUR√çSTICA IMPORTANTE")
            return self._get_fallback_response("IMPORTANTE")
        
        # Verificar profissional
        professional_indicators = ['reuni√£o', 'projeto', 'relat√≥rio', 'equipe', 'corporativo']
        professional_count = sum(1 for indicator in professional_indicators if indicator in content_lower)
        
        if professional_count >= 2:
            print(f"üéØ HEUR√çSTICA PROFISSIONAL: {professional_count} indicadores")
            return self._get_fallback_response("PROFISSIONAL")
        
        print("üìã Usando fallback ROTINA")
        return self._get_fallback_response("ROTINA")
    
    def _get_fallback_response(self, categoria: str) -> Dict:
        """Resposta de fallback padronizada - INCLUINDO EDUCACIONAL"""
        responses = {
            "CURRICULO": {
                'utilidade': 0.92,
                'categoria': 'CURRICULO',
                'resumo': 'Curr√≠culo profissional detectado via an√°lise heur√≠stica',
                'acao_necessaria': True,
                'tags': ['curriculo', 'profissional', 'tecnologia', 'fallback_nlp'],
                'resposta': '‚úÖ Curr√≠culo recebido com sucesso! Analisaremos suas qualifica√ß√µes.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['curriculo', 'profissional', 'tecnologia']}
            },
            "EDUCACIONAL": {
                'utilidade': 0.82,
                'categoria': 'EDUCACIONAL',
                'resumo': 'Comunica√ß√£o educacional detectada via an√°lise heur√≠stica',
                'acao_necessaria': True,
                'tags': ['educacional', 'ensino', 'academico', 'fallback_nlp'],
                'resposta': 'üéì Comunica√ß√£o educacional recebida. Processaremos sua solicita√ß√£o.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['educacional', 'ensino', 'academico']}
            },
            "SPAM": {
                'utilidade': 0.15,
                'categoria': 'SPAM',
                'resumo': 'Email promocional detectado via an√°lise heur√≠stica',
                'acao_necessaria': False,
                'tags': ['spam', 'promocao', 'marketing', 'fallback_nlp'],
                'resposta': '[Email promocional detectado]',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['promocao', 'desconto', 'oferta']}
            },
            "PHISHING": {
                'utilidade': 0.05,
                'categoria': 'PHISHING',
                'resumo': 'Poss√≠vel phishing detectado via heur√≠stica de seguran√ßa',
                'acao_necessaria': True,
                'tags': ['phishing', 'seguran√ßa', 'alerta', 'fallback_nlp'],
                'resposta': '‚ö†Ô∏è Email suspeito detectado. Tome cuidado.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['seguran√ßa', 'alerta', 'suspeito']}
            },
            "FINANCEIRO": {
                'utilidade': 0.88,
                'categoria': 'FINANCEIRO',
                'resumo': 'Documento financeiro identificado via heur√≠stica',
                'acao_necessaria': True,
                'tags': ['financeiro', 'documento', 'pagamento', 'fallback_nlp'],
                'resposta': 'Documento financeiro recebido para an√°lise.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['financeiro', 'documento', 'pagamento']}
            },
            "IMPORTANTE": {
                'utilidade': 0.85,
                'categoria': 'IMPORTANTE',
                'resumo': 'Email importante detectado via palavras-chave',
                'acao_necessaria': True,
                'tags': ['importante', 'urgente', 'prioridade', 'fallback_nlp'],
                'resposta': 'Email importante recebido. An√°lise priorit√°ria.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['importante', 'urgente', 'prioridade']}
            },
            "PROFISSIONAL": {
                'utilidade': 0.78,
                'categoria': 'PROFISSIONAL',
                'resumo': 'Email profissional detectado via an√°lise heur√≠stica',
                'acao_necessaria': False,
                'tags': ['profissional', 'corporativo', 'trabalho', 'fallback_nlp'],
                'resposta': 'Email profissional recebido. Retornaremos em breve.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': ['profissional', 'trabalho', 'empresa']}
            },
            "ROTINA": {
                'utilidade': 0.45,
                'categoria': 'ROTINA',
                'resumo': 'Email de rotina - an√°lise autom√°tica',
                'acao_necessaria': False,
                'tags': ['rotina', 'comum', 'correspondencia', 'fallback_nlp'],
                'resposta': 'Mensagem recebida. Agradecemos seu contato.',
                'fonte': 'fallback_nlp',
                'metadata': {'palavras_chave': []}
            }
        }
        
        return responses.get(categoria, responses["ROTINA"])